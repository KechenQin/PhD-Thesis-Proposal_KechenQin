\unnumberedchapter{Abstract} 
\chapter*{Abstract} 
\subsection*{\thesistitle}



Artificial intelligence (AI) is the broad science of mimicking human abilities, and machine learning is a specific subset of AI that trains a machine how to learn. The most common approach in machine learning is supervised learning, where one asks a model to learn a mapping from an input to an output variable, e.g. a document $x$ to a category $y$ it belongs to. However, $(x,y)$ pairs is not always enough for describing the input-output relationship. Some information is unobserved, but plays an important role in modeling the relationship. For example, in question answering one is typically given the answer $y$ for a training query $x$, but not the unobserved reasoning path leading to the answer. Similarly, in dialogue summarization, one may be given the dialogue transcript $x$ and the labeled summary-worthy sentences $y$, but not the discourse structure (e.g. discourse relation between two sentences), which is helpful but missing from the given information.

This thesis aims to develop and study novel paradigms that leverage latent information to bridge the gap between observed input data and the learning target. We apply latent variable modeling approaches on different real world tasks. The experimental results show that the state-of-the-art results can be improved without adding much complexity to the model, but just considering the latent information. Studying latent information can help human better understand the prediction process, and thus improve the interpretability of the model. Further evaluation on downstream tasks provides evidences of the inferred latent information being successfully utilized to solve related tasks.

